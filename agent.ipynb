{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent is comprised of a router using OpenAI function calling, and a set of three tools: a database lookup tool, a data analysis tool, and a code generator to create graphs.\n",
    "\n",
    "<img src=\"images/agent.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "The agent can lookup information from a local file, perform analysis on that information, and graph results. The example local file is a log of transactions at a local store. The agent can help the store owners understand trends and anomalies in their sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "import phoenix as px\n",
    "import os\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider\n",
    "\n",
    "from helper import get_openai_api_key\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the OpenAI client\n",
    "openai_api_key = get_openai_api_key()\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "MODEL = \"gpt-4o\" #\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"tracing-agent\"\n",
    "PHOENIX_COLLECTOR_ENDPOINT='http://localhost:6006'\n",
    "\n",
    "tracer_provider = register(\n",
    "  project_name=PROJECT_NAME,\n",
    "  endpoint=\"http://localhost:6006/v1/traces\",\n",
    "  set_global_tracer_provider=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all openAI calls\n",
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for manual tracing like tools\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database lookup tool works using three steps. \n",
    "\n",
    "<img src=\"images/tool1.png\" width=\"500\"/>\n",
    "\n",
    "1. First, it creates the SQL table from a local file, if not already done.\n",
    "2. Second, it translates the original prompt into an sql query (using an LLM call).\n",
    "3. Finally, it runs that query against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the transactional data\n",
    "TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'\n",
    "\n",
    "# step 1: read the parquet file into a DuckDB table\n",
    "df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\"\n",
    "\n",
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# code for tool 1\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"sales\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        with tracer.start_as_current_span(\n",
    "            \"execute_sql_query\", \n",
    "            openinference_span_kind=\"chain\"\n",
    "        ) as span:\n",
    "            span.set_input(sql_query)\n",
    "            # step 3: execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_data = lookup_sales_data(\"Show me all the sales for store 1320 on November 1st, 2021\")\n",
    "# print(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 2: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second tool can analyze the returned data and display conclusions to users.\n",
    "\n",
    "<img src=\"images/tool2.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 2\n",
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(analyze_sales_data(prompt=\"what trends do you see in this data\", \n",
    "#                          data=example_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 3: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third tool generates python code to create the requested graphs from the returned data of the first tool. It consists of two steps:\n",
    "<img src=\"images/tool3.png\" width=\"500\"/>\n",
    "1. First, it creates the chart configuration: chart type, title, data, lables for x-axis and y-axis (using an LLM call).\n",
    "2. Second, it generates the python code based on the chart configuration of the first step (using an LLM call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\"\n",
    "\n",
    "# code for step 1 of tool 3\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data, \n",
    "                                                         visualization_goal=visualization_goal)\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 3\n",
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\"\n",
    "\n",
    "# code for step 2 of tool 3\n",
    "@tracer.chain()\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 3\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = generate_visualization(example_data, \n",
    "#                               \"A bar chart of sales by product SKU. Put the product SKU on the x-axis and the sales on the y-axis.\")\n",
    "# print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Router"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the tools are defined, you can create the router. The router will take the original user input, and is responsible for calling any tools. After each tool call is completed, the agent will return to router to determine whether another tool should be called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The router is composed of a main loop method, and a method to handle the tool calls that you get back from the model.\n",
    "\n",
    "<img src=\"images/router.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \n",
    "                         \"content\": result, \n",
    "                         \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        # Router Span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\", openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "    \n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"AgentRun\", openinference_span_kind=\"agent\"\n",
    "    ) as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = start_main_span([{\"role\": \"user\", \n",
    "                           \"content\": \"Which stores did the best in 2021?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
